# The Ask

?> <img src="../media/dog.jpeg" width="200"> **Application Owner:** "We've observed a significant slowdown in a function called 'tempfiles' within our system. It used to be executed around **6,000** times in 10 minutes, but now it's only managing about **4,000** executions in the same period. Could you help us resolve this issue? I suspect it might be related to something called '**temporary files**'."

# Investigation

To address the issue raised by the Application Owner, our first step is to examine the generation of temporary files, which is likely impacting the function's performance.

### Accessing Query Performance Insight

1. **Open Query Performance Insight:** Look for the 'Query Performance Insight' option. This tool provides detailed insights into query performance, which is crucial for our investigation.
    <img src="../media/query-performance-insight.png">

2. **Select 'Top Queries by Temporary Files' Tab:** Within Query Performance Insight, navigate to the 'Top Queries by Temporary Files' tab. This section specifically focuses on queries that are generating temporary files.
    <img src="../media/top-queries-by-temp-files.png">

### Detailed Analysis of Temporary File Sizes

1. **Scroll Down for Detailed Metrics:** In the 'Top Queries by Temporary Files' tab, scroll down to view more detailed metrics about the temporary files generated by each query.

2. **MeanTempBlksWritten and MeanTempBlksRead Metrics:** Look for the 'MeanTempBlksWritten' and 'MeanTempBlksRead' columns. These metrics will show you the average size of temporary files generated by each execution of the query.

3. **TotalTempBlksWritten Metric:** The 'TotalTempBlksWritten' metric is also crucial. It represents the total amount of temporary file blocks written throughout all executions of the query.

<img src="../media/temp-files-metrics.png">

### Case Example

In our example, let's say the mean temporary file size per query execution is approximately 24 MB. However, when multiplied by the number of times the query has been executed, the total amount of temporary file data accumulates to a staggering 62 GB! This significant volume of temporary file generation could be a key factor in the slowdown of the system's function.

**Expected Outcome:** By examining these metrics, we gain a clear understanding of not just the presence of temporary files, but their size and total impact across all query executions. This detailed analysis is crucial for developing a strategy to address the excessive temporary file generation and optimize the function's performance.


Having analyzed the temporary file sizes, our next objective is to confirm if the query in question is indeed a call to the `tempfiles()` function, as mentioned by the Application Owner.

### Decrypting the Query ID

To accurately identify the query, we need to decrypt its ID. This involves connecting to your database instance and performing specific steps:

1. **Connect to Your Database Instance:** Log into your Azure Database for PostgreSQL.

2. **Access the `azure_sys` Database:** Navigate to the `azure_sys` database within your instance. For instance use this command: `psql azure_sys`.

3. **Execute the Query from Query Performance Insight:** On the Query Performance Insight page, scroll to the bottom to find the query in question. The queries are anonymized for privacy reasons, but you'll see a specific query ID provided. Execute this query within the `azure_sys` database to decrypt the ID and reveal the actual query.

<img src="../media/decrypt-query-id.png">


### Confirming the Function Call

Once you have executed the query with the query ID:

- Check the output to see if it corresponds to a call to the `tempfiles()` function.
- This step is crucial for confirming whether the identified performance issue is directly related to the function of concern.

**Expected Outcome:** By decrypting the query ID and examining the actual query, you will be able to determine if the performance issue is indeed linked to the `tempfiles()` function. This confirmation is key to moving forward with targeted optimization strategies.

<img src="../media/confirm-query-id.png">




## Monitoring the Changes

Once PgBouncer is enabled and the application is reconfigured to connect through port 6432, allow some time for the changes to reflect in metrics. Then, revisit the Azure metrics. You should observe a notable decrease in CPU utilization and a more manageable number of connections. This exercise demonstrates the effectiveness of PgBouncer in optimizing connection management and reducing CPU strain in Azure Database for PostgreSQL.




?> <img src="../media/dba-dog.png" width="200"> **Application Owner:** "Thank you! After enabling PgBouncer, I see that the CPU utilization went down by around 16 percent!"


![After redirecting connections through PgBouncer](../media/cpuPgBouncer.png)
